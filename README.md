# 신경망
### 퍼셉트론 알고리즘

퍼셉트론 -> 뉴런의 동작원리를 모형화 한 것

노드에 각 입력에 대해 입력값과 가중치를 곱한 값을 합한 다음 바이어스를 더한 값이 전달된다. 그 다음 활성화 함수가 노드에 전달된 값을 변환해서 출력값을 만든다.

`퍼셉트론`은 지도 학습 알고리즘이다.

퍼셉트론 알고리즘으로는 선형 분리가 불가능하다. 즉, 비선형 적인 문제를 풀 수 없다 -> 여러개의 퍼셉트론 이용하면 가능

`활성화 함수`로 `스텝함수`를 사용 (0 이상이어야 출력값이 1, 아니면 0)

### 신경망의 알고리즘

지도 학습 -> 설명 변수 + 목적 변수

퍼셉트론 여러개를 조합한 것이다.

활성화 함수로 `시그모이드`, `쌍곡선`, `ReLU` 함수 주로 사용

> 시그모이드 함수 -> [0,1] 치역
>
> 쌍곡선 함수 -> [-1,1] 치역
>
> ReLU 함수 -> 입력값이  0보다 작으면 함수값이 0이고, 반대의 경우 함수값은 입력값에 비례

출력층에서 문제의 목적이 `분류`이면 소프트맥스 함수 이용

문제의 목적이 `회귀`이면 항등함수 사용

입력층 -> 출력층 까지의 과정 -> `순전파`

> 소프트 맥스 함수는 모든 출력층 노드 출력값의 합이 1이 된다는 것이 특징이다.

신경망에서 가중치를 업데이트 하기 위해 오차와 오차함수 필요

> 분류문제 -> 오차함수로 `교차엔트로피` 이용
>
> 회귀문제 -> 오차함수로 `제곱오차` 이용

신경망을 학습시키기 위해서는 오차가 줄어들도록 가중치를 업데이트 시켜야됨

가중치 업데이트의 방법 : `경사하강법` -> 곡선의 밑바닥을 향해 간다

`배치학습` -> 가중치 한 번 업데이트 할 때 모든 데이터를 사용 (국소최적해에 빠지는 경우가 있다)

`미니배치학습` -> 데이터를 여러 갈래로 나누어 한 갈래씩 사용해 가중치를 업데이트 한다 (확률적 경사 하강법)

이러한 과정은 퍼셉트로의 역전파 과정이다.

출력층에서 입력층으로 오차가 거슬러 올라가며 전달되므로 오차 역전파 라고 한다. 순전파와 역전파 계산을 반복하면서 신경망의 정확도를 높여간다.

